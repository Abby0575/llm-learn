# llm-learn
# 这个博客旨在记录和分享大模型的学习过程和资源
一、Transformer架构
1. 注意力机制
   (1) 注意力机制的基本原理和计算公式

